# EDA â€” PrÃ©diction du Churn Client (dÃ©sabonnement) â€“ Projet Data Science 

### *Auteur :*__MACHAY Fatima__
### *Date :* __2025-10-06__
### *Objectif :*

DÃ©velopper un pipeline complet de Machine Learning supervisÃ© permettant de prÃ©dire le dÃ©sabonnement des clients (churn) au sein dâ€™une entreprise de tÃ©lÃ©communications, dans le but de mieux cibler les actions de fidÃ©lisation et de rÃ©duire la perte de clientÃ¨le. ParallÃ¨lement, analyser et explorer les donnÃ©es clients afin dâ€™identifier les facteurs clÃ©s qui influencent le risque de dÃ©sabonnement.


## PrÃ©sentation du Projet :

L'objectif de ce projet est de prÃ©dire le churn des clients dans une entreprise de tÃ©lÃ©communications, en utilisant des techniques d'apprentissage automatique. Le but principal est de construire un modÃ¨le prÃ©dictif capable de dÃ©terminer si un client va se dÃ©sabonner (churner) en fonction de ses attributs. Ce projet utilise plusieurs algorithmes de classification et Ã©value la performance des modÃ¨les avec des mÃ©triques telles que la prÃ©cision, le recall, le F1-score et l'AUC (Area Under the Curve).

## ğŸ“‘ Table des matiÃ¨res :

- [Gestion de projet](#gestion-de-projet)
- [ModÃ¨les implÃ©mentÃ©s](#modÃ¨les-implÃ©mentÃ©s)
- [Installation](#installation)
- [DonnÃ©es](#donnÃ©es)
- [PrÃ©traitement des DonnÃ©es](#PrÃ©traitement-des-DonnÃ©es)
- [ModÃ©lisation](#modÃ©lisation)
- [EntraÃ®nement et Ã‰valuation des ModÃ¨les](#EntraÃ®nement-et-Ã‰valuation-des-ModÃ¨les)
- [ExÃ©cution du projet](#exÃ©cution-du-projet)
- [Tests](#tests)
- [Contribuer](#contribuer)
- [Licence](#licence)

## PrÃ©sentation :

Le churn client dÃ©signe le phÃ©nomÃ¨ne oÃ¹ les clients cessent d'utiliser les services d'une entreprise. Pour les entreprises, prÃ©dire ce churn est crucial afin de mettre en place des stratÃ©gies de fidÃ©lisation et de rÃ©duction de la perte de clients. Dans ce projet, nous appliquons des algorithmes d'apprentissage automatique pour prÃ©dire si un client va churner, en fonction de diverses caractÃ©ristiques, telles que la dÃ©mographie, les dÃ©tails d'abonnement, et son comportement d'utilisation.

## ğŸ§© Gestion de projet :

La planification initiale a Ã©tÃ© rÃ©alisÃ©e avec [Jira](https://infofatimamachay.atlassian.net/jira/software/projects/KAN/list), afin de structurer les tÃ¢ches, suivre lâ€™avancement et mieux organiser les diffÃ©rentes Ã©tapes du dÃ©veloppement.

### ModÃ¨les ImplÃ©mentÃ©s :

- Classificateur Random Forest; 
- RÃ©gression Logistique; 
- Support Vector Classifier (SVC).

## Installation :

Pour dÃ©marrer avec ce projet, suivez les Ã©tapes ci-dessous :

__Clonez le dÃ©pÃ´t :__

[git clone](https://github.com/FatimaMachay7/Projet_Pr-diction-du-Churn-Client.git)

__AccÃ©dez au rÃ©pertoire du projet :__
      [cd]    Projet_Pr-diction-du-Churn-Client 

1. Installez les dÃ©pendances requises :

2. Installez les dÃ©pendances avec la commande `pip install -r requirements.txt`.
3. Installez manuellement les dÃ©pendances suivantes :

pip install pandas
pip install numpy
pip install scikit-learn
pip install matplotlib
pip install seaborn
pip install pytest

## ğŸ“ DonnÃ©es :

Les donnÃ©es utilisÃ©es dans ce projet proviennent du dataset Customer Churn Prediction. Ce dataset contient des informations concernant les clients : dÃ©mographie, dÃ©tails d'abonnement, comportement d'utilisation, et une colonne "Churn" qui indique si le client a churnÃ© (Oui) ou non (Non).

Les donnÃ©es sont disponibles ici :

[Voir le fichier Churn.csv](./DATA/churn.csv)


## PrÃ©traitement des DonnÃ©es :


*EDA â€” Exploration des DonnÃ©es (DonnÃ©es clients et Churn) :*

L'Exploration des DonnÃ©es (EDA) est une Ã©tape essentielle pour analyser la distribution des variables et leurs interactions. Elle permet de mieux identifier les facteurs clÃ©s qui influencent le churn des clients. Cette analyse dÃ©taillÃ©e a Ã©tÃ© rÃ©alisÃ©e Ã  lâ€™aide dâ€™un *notebook Jupyter*, offrant un aperÃ§u complet du dataset.

*Analyse Descriptive des DonnÃ©es :* 

Les statistiques descriptives des variables principales sont fournies ci-dessous :

------------------------->`data.describe()`<--------------------------------------------------


| Feature         | SeniorCitizen | tenure     | MonthlyCharges |
|----------------|---------------|------------|----------------|
| **count**       | 7043.000000   | 7043.000000| 7043.000000    |
| **mean**        | 0.162147      | 32.371149  | 64.761692      |
| **std**         | 0.368612      | 24.559481  | 30.090047      |
| **min**         | 0.000000      | 0.000000   | 18.250000      |
| **25%**         | 0.000000      | 9.000000   | 35.500000      |
| **50% (median)**| 0.000000      | 29.000000  | 70.350000      |
| **75%**         | 0.000000      | 55.000000  | 89.850000      |
| **max**         | 1.000000      | 72.000000  | 118.750000     |

L'Exploration des DonnÃ©es (EDA) inclut lâ€™analyse des distributions et des relations entre variables, ainsi que des *visualisations* pour mieux comprendre les donnÃ©es. Les *histogrammes* sont utilisÃ©s pour les variables numÃ©riques, tandis que les *countplots* sont privilÃ©giÃ©s pour les variables catÃ©gorielles. Les *subplots* permettent de comparer plusieurs visualisations simultanÃ©ment. Ces outils permettent dâ€™identifier des patterns, des anomalies et d'analyser les variables avant l'entraÃ®nement du modÃ¨le.

Voici un graphique montrant l'Ã©volution du churn des clients :

__Histogramme de la variable *Tenure* :__
![Graphique du tenure](Graphes_EDA/histogramme_tenure.png)

__Histogramme de la  variable *MonthlyCharges* :__
![Graphique du MonthlyCharges](Graphes_EDA/histogramme_MonthlyCharges.png)

__Subplot comparant *les variables catÃ©gorielles :*__

![Subplot comparant les variables catÃ©gorielles](Graphes_EDA/count_polt.png)

__ğŸ“ˆ Matrice de corrÃ©lation : comprÃ©hension des liens entre les variables :__

![La matrice de corrÃ©lation](Graphes_EDA/matrice_correlation.png)

*Relations entre les Variables  :*

L'Analyse Exploratoire des DonnÃ©es (EDA) permet d'Ã©tudier les relations entre les variables et de prÃ©parer les donnÃ©es pour les modÃ¨les de machine learning. Les donnÃ©es ont Ã©tÃ© chargÃ©es Ã  l'aide de Pandas, et la variable cible sÃ©lectionnÃ©e est churn. Les variables gender, seniorCitizen, partner, et customerID ont Ã©tÃ© exclues en raison de leur faible influence sur la prÃ©diction du churn. L'encodage des variables catÃ©gorielles, ainsi que de churn et TotalCharges, a Ã©tÃ© effectuÃ© Ã  l'aide de Label Encoding afin de rendre ces donnÃ©es compatibles avec les modÃ¨les de machine learning.

InterprÃ©tation de la matrice de corrÃ©lation : La matrice rÃ©vÃ¨le des relations significatives entre certaines variables, telles que la corrÃ©lation entre charges mensuelles et tenure, ce qui permet de mieux orienter la sÃ©lection des features.


*SÃ©paration Train-Test :* Le jeu de donnÃ©es est divisÃ© en un ensemble dâ€™entraÃ®nement et un ensemble de test avec train_test_split.

*Normalisation des DonnÃ©es :* AprÃ¨s la sÃ©paration des donnÃ©es en ensembles d'entraÃ®nement et de test, nous appliquons une normalisation pour uniformiser l'Ã©chelle des caractÃ©ristiques. Cela est fait avec MinMaxScaler de sklearn, qui redimensionne les valeurs des variables dans un intervalle spÃ©cifiÃ©, gÃ©nÃ©ralement entre [0, 1]. Cette Ã©tape garantit que toutes les caractÃ©ristiques sont sur une Ã©chelle comparable.


## ModÃ©lisation :

Trois modÃ¨les sont utilisÃ©s pour la prÃ©diction du churn :

- Classificateur Random Forest; 
- RÃ©gression Logistique; 
- Support Vector Classifier (SVC).

## EntraÃ®nement et Ã‰valuation des ModÃ¨les :

Chaque modÃ¨le est Ã©valuÃ© sur des mÃ©triques telles que :

- PrÃ©cision (Accuracy); 
- PrÃ©cision (Precision); 
- Rappel (Recall);
- F1-Score;
- ROC- curve.

*DÃ©cision basÃ©e sur la comparaison des modÃ¨les :*

AprÃ¨s Ã©valuation des trois modÃ¨les (*Random Forest, RÃ©gression Logistique, SVC*) sur des mÃ©triques clÃ©s, voici les rÃ©sultats :

*RÃ©gression Logistique* excelle en rappel (0.8284), idÃ©ale pour identifier les churners (minimiser les faux nÃ©gatifs).

*SVC* se distingue par la meilleure ROC-AUC (0.84), offrant une bonne discrimination entre churn et non-churn.

*Random Forest* a la meilleure accuracy (0.7828), mais un rappel plus faible (0.4665), ce qui en fait un modÃ¨le Ã©quilibrÃ© pour des prÃ©dictions globales.

Le meilleur modÃ¨le que j'ai choisi est la *RÃ©gression Logistique*, car elle offre le meilleur compromis entre rappel et F1-Score, ce qui est crucial pour ce projet.

## ExÃ©cution du Projet :


- Ouvrez le fichier Data_Churn.ipynb et exÃ©cutez les cellules dans lâ€™ordre.

- Le notebook entraÃ®nera les trois modÃ¨les : RÃ©gression Logistique, Random Forest et SVC.

- Le notebook effectuera les Ã©tapes suivantes :
*Chargement des donnÃ©es;*
*PrÃ©traitement des donnÃ©es;*
*EntraÃ®nement de chaque modÃ¨le;*
*Ã‰valuation de la performance de chaque modÃ¨le;*
*TracÃ© des courbes pour la comparaison.*

## Tests :

Le projet inclut des tests unitaires pour vÃ©rifier :

- La cohÃ©rence des dimensions entre les variables dâ€™entraÃ®nement et de test;
- Lâ€™Ã©valuation correcte des modÃ¨les.

_Pour exÃ©cuter les tests :_

*pytest*

Cela exÃ©cutera tous les tests dans le rÃ©pertoire tests/.

## Contribuer :

Les contributions sont les bienvenues ! Si vous trouvez un bug ou souhaitez amÃ©liorer le projet, nâ€™hÃ©sitez pas Ã  forker le dÃ©pÃ´t et soumettre une demande de pull.

Pour contribuer :

- Forkez le dÃ©pÃ´t.
- CrÃ©ez une nouvelle branche.
- Effectuez vos modifications.
- Soumettez une demande de pull.

## Licence :

_Ce projet est sous licence MIT. Consultez le fichier LICENSE pour plus de dÃ©tails._